2014-01-25 06:06:58+0000 [scrapy] INFO: Enabled extensions: LogStats, TelnetConsole, CloseSpider, WebService, CoreStats, MemoryUsage, MemoryDebugger, SpiderState
2014-01-25 06:06:58+0000 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2014-01-25 06:06:58+0000 [scrapy] INFO: LimitRequestMiddleware Init
2014-01-25 06:06:58+0000 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, LimitRequestMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2014-01-25 06:06:58+0000 [scrapy] INFO: Enabled item pipelines: AllPipeline
2014-01-25 06:06:58+0000 [testscrape] INFO: Spider opened
2014-01-25 06:06:58+0000 [testscrape] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2014-01-25 06:06:58+0000 [Uninitialized] ERROR: Log observer <bound method ScrapyFileLogObserver._emit of <scrapy.log.ScrapyFileLogObserver instance at 0x23170e0>> failed.
	Traceback (most recent call last):
	  File "/usr/lib64/python2.7/site-packages/twisted/internet/defer.py", line 490, in _startRunCallbacks
	    self._runCallbacks()
	  File "/usr/lib64/python2.7/site-packages/twisted/internet/defer.py", line 577, in _runCallbacks
	    current.result = callback(current.result, *args, **kw)
	  File "/usr/lib/python2.7/site-packages/scrapy/log.py", line 130, in msg
	    log.msg(message, **kw)
	  File "/usr/lib64/python2.7/site-packages/twisted/python/threadable.py", line 53, in sync
	    return function(self, *args, **kwargs)
	--- <exception caught here> ---
	  File "/usr/lib64/python2.7/site-packages/twisted/python/log.py", line 191, in msg
	    self.observers[i](actualEventDict)
	  File "/usr/lib/python2.7/site-packages/scrapy/log.py", line 46, in _emit
	    ev = _adapt_eventdict(eventDict, self.level, self.encoding)
	  File "/usr/lib/python2.7/site-packages/scrapy/log.py", line 85, in _adapt_eventdict
	    message = [unicode_to_str(x, encoding) for x in message]
	  File "/usr/lib/python2.7/site-packages/scrapy/utils/python.py", line 97, in unicode_to_str
	    raise TypeError('unicode_to_str must receive a unicode or str object, got %s' % type(text).__name__)
	exceptions.TypeError: unicode_to_str must receive a unicode or str object, got instance
	
2014-01-25 06:06:58+0000 [testscrape] INFO: Closing spider (finished)
2014-01-25 06:06:58+0000 [testscrape] INFO: Dumping Scrapy stats:
	{'downloader/exception_count': 1,
	 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 1,
	 'downloader/request_bytes': 224,
	 'downloader/request_count': 1,
	 'downloader/request_method_count/GET': 1,
	 'finish_reason': 'finished',
	 'finish_time': datetime.datetime(2014, 1, 25, 6, 6, 58, 210976),
	 'memdebug/gc_garbage_count': 0,
	 'memdebug/live_refs/SpiderAll': 1,
	 'memusage/max': 46813184,
	 'memusage/startup': 46813184,
	 'scheduler/dequeued': 1,
	 'scheduler/dequeued/disk': 1,
	 'scheduler/enqueued': 1,
	 'scheduler/enqueued/disk': 1,
	 'start_time': datetime.datetime(2014, 1, 25, 6, 6, 58, 199136)}
2014-01-25 06:06:58+0000 [testscrape] INFO: Spider closed (finished)
